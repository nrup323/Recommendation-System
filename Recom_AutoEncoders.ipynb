{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recom_AutoEncoders.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4f4JG1gdKqj"
      },
      "source": [
        "#AutoEncoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jbiqOK7dLGG"
      },
      "source": [
        "##Downloading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL5MEkLcfRD2"
      },
      "source": [
        "###ML-100K\n",
        "\n",
        "We will use this dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjOPzue7FCXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29fc0145-4d32-4ee4-ded6-7644130dd6fe"
      },
      "source": [
        "!wget \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "!unzip ml-100k.zip\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-14 13:14:00--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  9.96MB/s    in 0.5s    \n",
            "\n",
            "2021-08-14 13:14:01 (9.96 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n",
            "ml-100k  ml-100k.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xis6ldDfTs6"
      },
      "source": [
        "###ML-1M"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOly1yfAfTjd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7f8c37-eebe-41cb-fc70-66fa0ffcfed7"
      },
      "source": [
        "!wget \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
        "!unzip ml-1m.zip\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-14 13:14:02--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  10.5MB/s    in 0.5s    \n",
            "\n",
            "2021-08-14 13:14:03 (10.5 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n",
            "ml-100k  ml-100k.zip  ml-1m  ml-1m.zip\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOBJ8UCXdY0g"
      },
      "source": [
        "##Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LvGeU1CeCtg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable #fro stochastic gradient decent\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm  # tqdm is for progress bar\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM04FyMudkoK"
      },
      "source": [
        "## Importing the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJw2p3-Cewo4"
      },
      "source": [
        "# We won't be using this dataset.\n",
        "#this is just to see how is data presented\n",
        "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "\n",
        "#none as there are no headers\n",
        "#movie title contains the special characters therefore encoding latin-1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHAhHfd5znbs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "82422b3d-8979-40da-93e5-effb6c2bf323"
      },
      "source": [
        "movies.head()\n",
        "#movies.info()\n",
        "ratings.info()\n",
        "ratings.head()\n",
        "#userd id, movie id, rating"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000209 entries, 0 to 1000208\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count    Dtype\n",
            "---  ------  --------------    -----\n",
            " 0   0       1000209 non-null  int64\n",
            " 1   1       1000209 non-null  int64\n",
            " 2   2       1000209 non-null  int64\n",
            " 3   3       1000209 non-null  int64\n",
            "dtypes: int64(4)\n",
            "memory usage: 30.5 MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>661</td>\n",
              "      <td>3</td>\n",
              "      <td>978302109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>914</td>\n",
              "      <td>3</td>\n",
              "      <td>978301968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3408</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0     1  2          3\n",
              "0  1  1193  5  978300760\n",
              "1  1   661  3  978302109\n",
              "2  1   914  3  978301968\n",
              "3  1  3408  4  978300275\n",
              "4  1  2355  5  978824291"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTIbE2tkdkwP"
      },
      "source": [
        "## Preparing the training set and the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2usLKJBEgPE2"
      },
      "source": [
        "# we will be using this data\n",
        "#base is a training\n",
        "training_set = pd.read_csv('ml-100k/u1.base',header=None, delimiter = '\\t')\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = pd.read_csv('ml-100k/u1.test',header = None, delimiter = '\\t')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wrKVb9jHqM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c8f329-af3e-481a-a846-ba757c932ee5"
      },
      "source": [
        "training_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[        1,         1,         5, 874965758],\n",
              "       [        1,         2,         3, 876893171],\n",
              "       [        1,         3,         4, 878542960],\n",
              "       ...,\n",
              "       [      943,      1188,         3, 888640250],\n",
              "       [      943,      1228,         3, 888640275],\n",
              "       [      943,      1330,         3, 888692465]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCf8HjSydk4s"
      },
      "source": [
        "## Getting the number of users and movies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_yqf0cnEaEm"
      },
      "source": [
        "we need to create an array where we have alll the ows as users and columsn corrresponding to movies and cell corresponding to them will be the rating of the movie i by user j"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPe7P81Z1e1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dca4562-0c95-4113-a8f0-0d7dd7a10cea"
      },
      "source": [
        "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))\n",
        "print(nb_users, nb_movies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "943 1682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-w4-hVidlAm"
      },
      "source": [
        "## Converting the data into an array with users in lines and movies in columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM7EDWylJ89J"
      },
      "source": [
        "dataset size willl include all the no. of users and movies for both training set and test and we wioll put zero where we dont have data or"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji7XlXljGqcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "837a024a-01c0-41b8-bba6-9f640cdc672c"
      },
      "source": [
        "# Creating a matrix where cell u,i is a rating given by user u to the ith movie and if no rating is given put 0 there\n",
        "data = np.zeros((nb_users, nb_movies))\n",
        "data.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(943, 1682)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezQ-AaP3HWGU"
      },
      "source": [
        "for i in range(len(training_set[:,0])):\n",
        "  user = training_set[i,0]\n",
        "  movie = training_set[i,1]\n",
        "  data[user-1, movie-1]  = training_set[i,2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJxD7VkqNuUN"
      },
      "source": [
        "#defining a function out of above for loop\n",
        "\n",
        "def con(data):\n",
        "  new_data = np.zeros((nb_users, nb_movies))\n",
        "  for i in range(len(data[:,0])):\n",
        "    user = data[i,0]\n",
        "    movie = data[i,1]\n",
        "    new_data[user-1, movie-1] = data[i,2]\n",
        "  return new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFsnMIU1OS4-"
      },
      "source": [
        "new_data = con(training_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OdYrKFRH1ax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e256bffe-6d5c-4a8f-e35f-9c290a08b717"
      },
      "source": [
        "t = np.random.rand(3,3)\n",
        "print(t)\n",
        "print(t[0][1], t[0,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.87318725 0.58930777 0.03518272]\n",
            " [0.21414112 0.13476178 0.92699089]\n",
            " [0.56616435 0.51015129 0.78331997]]\n",
            "0.5893077734340606 0.5893077734340606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6JdMcSuH_aY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f6f3cb4-13c5-4523-af3b-fe752febfafd"
      },
      "source": [
        "print(len(training_set[:,0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg6YuTpvIuRT"
      },
      "source": [
        "training_set = con(training_set)\n",
        "test_set  = con(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix7y_LDlOvKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "367583c3-819b-43fc-95d7-ba85e7348a7e"
      },
      "source": [
        "for i in range(5):\n",
        "  print(training_set[i] , test_set[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5. 3. 4. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.]\n",
            "[4. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.]\n",
            "[0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.]\n",
            "[0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.]\n",
            "[0. 0. 0. ... 0. 0. 0.] [4. 3. 0. ... 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1prFajHDPxko"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMmhuUpldlHo"
      },
      "source": [
        "## Converting the data into Torch tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ItW8oXBIC3x"
      },
      "source": [
        "training_set = torch.from_numpy(training_set)\n",
        "test_set = torch.from_numpy(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR94hFyGQILj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "365341f9-9906-4610-c5cb-99f27efba17e"
      },
      "source": [
        "training_set.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'torch.DoubleTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTGa_3W5S5c-"
      },
      "source": [
        "training_set  = training_set.float()\n",
        "test_set  = test_set.float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu3Oa_9ZTlm8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "04100688-7c61-4fe6-d10f-a77fce5e761a"
      },
      "source": [
        "training_set.type()\n",
        "test_set.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kkL8NkkdlZj"
      },
      "source": [
        "## Creating the architecture of the Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lmcQ70rT7Hu"
      },
      "source": [
        "# we will build a class\n",
        "# stacked autoencoder we will use the inheritance\n",
        "# we will creat a child class form parant class Module adn we will be able to use\n",
        "#all the funtions and variable from parent class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTA_HUcuU2OR"
      },
      "source": [
        "class SAE(nn.Module):\n",
        "  # in heritance is done\n",
        "  def __init__(self, ):\n",
        "    super(SAE, self).__init__()\n",
        "    #we optimize it helps using functionalitiers form parent class\n",
        "    #to get inherit methods from Modules\n",
        "    #connection bwtween input and first encoded vector full connection\n",
        "    self.fc1 = nn.Linear(nb_movies, 20)\n",
        "    self.fc2 = nn.Linear(20,10)\n",
        "    self.fc3 = nn.Linear(10,20)\n",
        "    self.fc4 = nn.Linear(20,nb_movies)\n",
        "    #specify an activation fucntions\n",
        "    self.Activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.Activation(self.fc1(x))\n",
        "    x = self.Activation(self.fc2(x))\n",
        "    x = self.Activation(self.fc3(x))\n",
        "    x = self.fc4(x) # we dont use activations here\n",
        "    return x #this is the vector of predicted ratings\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLcXxUvHeDme"
      },
      "source": [
        "sae=SAE()\n",
        "criterion = nn.MSELoss()\n",
        "opt = optim.RMSprop( params = sae.parameters(), lr = 0.01, weight_decay = 0.5 )#weight_decayas regularizes the learning rate after each epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq1FaFNceRdL",
        "outputId": "8e3e020f-0a89-4042-b807-383461850f1e"
      },
      "source": [
        "criterion\n",
        "opt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RMSprop (\n",
              "Parameter Group 0\n",
              "    alpha: 0.99\n",
              "    centered: False\n",
              "    eps: 1e-08\n",
              "    lr: 0.01\n",
              "    momentum: 0\n",
              "    weight_decay: 0.5\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D_bYk8c8lAn",
        "outputId": "b17fec73-49fa-46b5-e27e-b122a3c0bc7b"
      },
      "source": [
        "nb_movies"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1682"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gy59alAdloL"
      },
      "source": [
        "## Training the SAE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpDUjSxggJ-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb34558e-9112-4e5e-e8dd-84a4bd3b2b79"
      },
      "source": [
        "#optimize the code for bigger dataset\n",
        "epochs = 200\n",
        "train_loss_list = []\n",
        "for epoch in range(1, epochs+ 1):\n",
        "  train_loss = 0\n",
        "  #excluding the users who did not rate\n",
        "  s = 0.0 #float\n",
        "  for id_user in range(nb_users):\n",
        "    input = training_set[id_user]\n",
        "    input = Variable(input).unsqueeze(0)#create a new dimenion at 0 index in shape\n",
        "    target = input.clone()\n",
        "    #output = sae(input)#additional dimenstion for the batch\n",
        "    if (torch.sum(input)>0):\n",
        "       output = sae(input)\n",
        "       #optimizing memory and computation\n",
        "       target.require_grad =  False\n",
        "       output[target == 0] = 0\n",
        "       loss = criterion(output, target)\n",
        "       mean_corrector = nb_movies/(float(torch.sum(target.data>0)) + 1e-10)\n",
        "       loss.backward()#weights will increase or decrease\n",
        "       train_loss = train_loss + torch.sqrt((loss*mean_corrector))\n",
        "       s = s + 1.\n",
        "       opt.step()# by how weight will decrease or increase\n",
        "  print('Epoch: '+ str(epoch) + \" loss : \" + str(train_loss/s) )\n",
        "  train_loss_list.append(train_loss)\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 loss : tensor(1.7714, grad_fn=<DivBackward0>)\n",
            "Epoch: 2 loss : tensor(1.0968, grad_fn=<DivBackward0>)\n",
            "Epoch: 3 loss : tensor(1.0535, grad_fn=<DivBackward0>)\n",
            "Epoch: 4 loss : tensor(1.0383, grad_fn=<DivBackward0>)\n",
            "Epoch: 5 loss : tensor(1.0308, grad_fn=<DivBackward0>)\n",
            "Epoch: 6 loss : tensor(1.0266, grad_fn=<DivBackward0>)\n",
            "Epoch: 7 loss : tensor(1.0238, grad_fn=<DivBackward0>)\n",
            "Epoch: 8 loss : tensor(1.0222, grad_fn=<DivBackward0>)\n",
            "Epoch: 9 loss : tensor(1.0206, grad_fn=<DivBackward0>)\n",
            "Epoch: 10 loss : tensor(1.0194, grad_fn=<DivBackward0>)\n",
            "Epoch: 11 loss : tensor(1.0187, grad_fn=<DivBackward0>)\n",
            "Epoch: 12 loss : tensor(1.0186, grad_fn=<DivBackward0>)\n",
            "Epoch: 13 loss : tensor(1.0179, grad_fn=<DivBackward0>)\n",
            "Epoch: 14 loss : tensor(1.0174, grad_fn=<DivBackward0>)\n",
            "Epoch: 15 loss : tensor(1.0173, grad_fn=<DivBackward0>)\n",
            "Epoch: 16 loss : tensor(1.0168, grad_fn=<DivBackward0>)\n",
            "Epoch: 17 loss : tensor(1.0171, grad_fn=<DivBackward0>)\n",
            "Epoch: 18 loss : tensor(1.0164, grad_fn=<DivBackward0>)\n",
            "Epoch: 19 loss : tensor(1.0165, grad_fn=<DivBackward0>)\n",
            "Epoch: 20 loss : tensor(1.0165, grad_fn=<DivBackward0>)\n",
            "Epoch: 21 loss : tensor(1.0160, grad_fn=<DivBackward0>)\n",
            "Epoch: 22 loss : tensor(1.0162, grad_fn=<DivBackward0>)\n",
            "Epoch: 23 loss : tensor(1.0158, grad_fn=<DivBackward0>)\n",
            "Epoch: 24 loss : tensor(1.0157, grad_fn=<DivBackward0>)\n",
            "Epoch: 25 loss : tensor(1.0158, grad_fn=<DivBackward0>)\n",
            "Epoch: 26 loss : tensor(1.0157, grad_fn=<DivBackward0>)\n",
            "Epoch: 27 loss : tensor(1.0156, grad_fn=<DivBackward0>)\n",
            "Epoch: 28 loss : tensor(1.0150, grad_fn=<DivBackward0>)\n",
            "Epoch: 29 loss : tensor(1.0130, grad_fn=<DivBackward0>)\n",
            "Epoch: 30 loss : tensor(1.0120, grad_fn=<DivBackward0>)\n",
            "Epoch: 31 loss : tensor(1.0097, grad_fn=<DivBackward0>)\n",
            "Epoch: 32 loss : tensor(1.0086, grad_fn=<DivBackward0>)\n",
            "Epoch: 33 loss : tensor(1.0043, grad_fn=<DivBackward0>)\n",
            "Epoch: 34 loss : tensor(1.0053, grad_fn=<DivBackward0>)\n",
            "Epoch: 35 loss : tensor(1.0008, grad_fn=<DivBackward0>)\n",
            "Epoch: 36 loss : tensor(0.9999, grad_fn=<DivBackward0>)\n",
            "Epoch: 37 loss : tensor(0.9968, grad_fn=<DivBackward0>)\n",
            "Epoch: 38 loss : tensor(0.9974, grad_fn=<DivBackward0>)\n",
            "Epoch: 39 loss : tensor(0.9934, grad_fn=<DivBackward0>)\n",
            "Epoch: 40 loss : tensor(0.9940, grad_fn=<DivBackward0>)\n",
            "Epoch: 41 loss : tensor(0.9911, grad_fn=<DivBackward0>)\n",
            "Epoch: 42 loss : tensor(0.9894, grad_fn=<DivBackward0>)\n",
            "Epoch: 43 loss : tensor(0.9896, grad_fn=<DivBackward0>)\n",
            "Epoch: 44 loss : tensor(0.9843, grad_fn=<DivBackward0>)\n",
            "Epoch: 45 loss : tensor(0.9836, grad_fn=<DivBackward0>)\n",
            "Epoch: 46 loss : tensor(0.9880, grad_fn=<DivBackward0>)\n",
            "Epoch: 47 loss : tensor(0.9854, grad_fn=<DivBackward0>)\n",
            "Epoch: 48 loss : tensor(0.9843, grad_fn=<DivBackward0>)\n",
            "Epoch: 49 loss : tensor(0.9854, grad_fn=<DivBackward0>)\n",
            "Epoch: 50 loss : tensor(0.9846, grad_fn=<DivBackward0>)\n",
            "Epoch: 51 loss : tensor(0.9796, grad_fn=<DivBackward0>)\n",
            "Epoch: 52 loss : tensor(0.9816, grad_fn=<DivBackward0>)\n",
            "Epoch: 53 loss : tensor(0.9766, grad_fn=<DivBackward0>)\n",
            "Epoch: 54 loss : tensor(0.9793, grad_fn=<DivBackward0>)\n",
            "Epoch: 55 loss : tensor(0.9731, grad_fn=<DivBackward0>)\n",
            "Epoch: 56 loss : tensor(0.9742, grad_fn=<DivBackward0>)\n",
            "Epoch: 57 loss : tensor(0.9707, grad_fn=<DivBackward0>)\n",
            "Epoch: 58 loss : tensor(0.9677, grad_fn=<DivBackward0>)\n",
            "Epoch: 59 loss : tensor(0.9748, grad_fn=<DivBackward0>)\n",
            "Epoch: 60 loss : tensor(0.9741, grad_fn=<DivBackward0>)\n",
            "Epoch: 61 loss : tensor(0.9685, grad_fn=<DivBackward0>)\n",
            "Epoch: 62 loss : tensor(0.9673, grad_fn=<DivBackward0>)\n",
            "Epoch: 63 loss : tensor(0.9637, grad_fn=<DivBackward0>)\n",
            "Epoch: 64 loss : tensor(0.9619, grad_fn=<DivBackward0>)\n",
            "Epoch: 65 loss : tensor(0.9590, grad_fn=<DivBackward0>)\n",
            "Epoch: 66 loss : tensor(0.9617, grad_fn=<DivBackward0>)\n",
            "Epoch: 67 loss : tensor(0.9603, grad_fn=<DivBackward0>)\n",
            "Epoch: 68 loss : tensor(0.9587, grad_fn=<DivBackward0>)\n",
            "Epoch: 69 loss : tensor(0.9547, grad_fn=<DivBackward0>)\n",
            "Epoch: 70 loss : tensor(0.9563, grad_fn=<DivBackward0>)\n",
            "Epoch: 71 loss : tensor(0.9582, grad_fn=<DivBackward0>)\n",
            "Epoch: 72 loss : tensor(0.9589, grad_fn=<DivBackward0>)\n",
            "Epoch: 73 loss : tensor(0.9499, grad_fn=<DivBackward0>)\n",
            "Epoch: 74 loss : tensor(0.9515, grad_fn=<DivBackward0>)\n",
            "Epoch: 75 loss : tensor(0.9477, grad_fn=<DivBackward0>)\n",
            "Epoch: 76 loss : tensor(0.9499, grad_fn=<DivBackward0>)\n",
            "Epoch: 77 loss : tensor(0.9459, grad_fn=<DivBackward0>)\n",
            "Epoch: 78 loss : tensor(0.9478, grad_fn=<DivBackward0>)\n",
            "Epoch: 79 loss : tensor(0.9450, grad_fn=<DivBackward0>)\n",
            "Epoch: 80 loss : tensor(0.9463, grad_fn=<DivBackward0>)\n",
            "Epoch: 81 loss : tensor(0.9439, grad_fn=<DivBackward0>)\n",
            "Epoch: 82 loss : tensor(0.9456, grad_fn=<DivBackward0>)\n",
            "Epoch: 83 loss : tensor(0.9454, grad_fn=<DivBackward0>)\n",
            "Epoch: 84 loss : tensor(0.9436, grad_fn=<DivBackward0>)\n",
            "Epoch: 85 loss : tensor(0.9421, grad_fn=<DivBackward0>)\n",
            "Epoch: 86 loss : tensor(0.9437, grad_fn=<DivBackward0>)\n",
            "Epoch: 87 loss : tensor(0.9422, grad_fn=<DivBackward0>)\n",
            "Epoch: 88 loss : tensor(0.9412, grad_fn=<DivBackward0>)\n",
            "Epoch: 89 loss : tensor(0.9388, grad_fn=<DivBackward0>)\n",
            "Epoch: 90 loss : tensor(0.9423, grad_fn=<DivBackward0>)\n",
            "Epoch: 91 loss : tensor(0.9413, grad_fn=<DivBackward0>)\n",
            "Epoch: 92 loss : tensor(0.9426, grad_fn=<DivBackward0>)\n",
            "Epoch: 93 loss : tensor(0.9397, grad_fn=<DivBackward0>)\n",
            "Epoch: 94 loss : tensor(0.9401, grad_fn=<DivBackward0>)\n",
            "Epoch: 95 loss : tensor(0.9384, grad_fn=<DivBackward0>)\n",
            "Epoch: 96 loss : tensor(0.9381, grad_fn=<DivBackward0>)\n",
            "Epoch: 97 loss : tensor(0.9385, grad_fn=<DivBackward0>)\n",
            "Epoch: 98 loss : tensor(0.9405, grad_fn=<DivBackward0>)\n",
            "Epoch: 99 loss : tensor(0.9444, grad_fn=<DivBackward0>)\n",
            "Epoch: 100 loss : tensor(0.9444, grad_fn=<DivBackward0>)\n",
            "Epoch: 101 loss : tensor(0.9423, grad_fn=<DivBackward0>)\n",
            "Epoch: 102 loss : tensor(0.9429, grad_fn=<DivBackward0>)\n",
            "Epoch: 103 loss : tensor(0.9396, grad_fn=<DivBackward0>)\n",
            "Epoch: 104 loss : tensor(0.9399, grad_fn=<DivBackward0>)\n",
            "Epoch: 105 loss : tensor(0.9350, grad_fn=<DivBackward0>)\n",
            "Epoch: 106 loss : tensor(0.9359, grad_fn=<DivBackward0>)\n",
            "Epoch: 107 loss : tensor(0.9330, grad_fn=<DivBackward0>)\n",
            "Epoch: 108 loss : tensor(0.9347, grad_fn=<DivBackward0>)\n",
            "Epoch: 109 loss : tensor(0.9324, grad_fn=<DivBackward0>)\n",
            "Epoch: 110 loss : tensor(0.9341, grad_fn=<DivBackward0>)\n",
            "Epoch: 111 loss : tensor(0.9320, grad_fn=<DivBackward0>)\n",
            "Epoch: 112 loss : tensor(0.9325, grad_fn=<DivBackward0>)\n",
            "Epoch: 113 loss : tensor(0.9313, grad_fn=<DivBackward0>)\n",
            "Epoch: 114 loss : tensor(0.9316, grad_fn=<DivBackward0>)\n",
            "Epoch: 115 loss : tensor(0.9309, grad_fn=<DivBackward0>)\n",
            "Epoch: 116 loss : tensor(0.9313, grad_fn=<DivBackward0>)\n",
            "Epoch: 117 loss : tensor(0.9302, grad_fn=<DivBackward0>)\n",
            "Epoch: 118 loss : tensor(0.9300, grad_fn=<DivBackward0>)\n",
            "Epoch: 119 loss : tensor(0.9291, grad_fn=<DivBackward0>)\n",
            "Epoch: 120 loss : tensor(0.9307, grad_fn=<DivBackward0>)\n",
            "Epoch: 121 loss : tensor(0.9290, grad_fn=<DivBackward0>)\n",
            "Epoch: 122 loss : tensor(0.9296, grad_fn=<DivBackward0>)\n",
            "Epoch: 123 loss : tensor(0.9281, grad_fn=<DivBackward0>)\n",
            "Epoch: 124 loss : tensor(0.9290, grad_fn=<DivBackward0>)\n",
            "Epoch: 125 loss : tensor(0.9280, grad_fn=<DivBackward0>)\n",
            "Epoch: 126 loss : tensor(0.9284, grad_fn=<DivBackward0>)\n",
            "Epoch: 127 loss : tensor(0.9275, grad_fn=<DivBackward0>)\n",
            "Epoch: 128 loss : tensor(0.9273, grad_fn=<DivBackward0>)\n",
            "Epoch: 129 loss : tensor(0.9264, grad_fn=<DivBackward0>)\n",
            "Epoch: 130 loss : tensor(0.9263, grad_fn=<DivBackward0>)\n",
            "Epoch: 131 loss : tensor(0.9262, grad_fn=<DivBackward0>)\n",
            "Epoch: 132 loss : tensor(0.9262, grad_fn=<DivBackward0>)\n",
            "Epoch: 133 loss : tensor(0.9256, grad_fn=<DivBackward0>)\n",
            "Epoch: 134 loss : tensor(0.9260, grad_fn=<DivBackward0>)\n",
            "Epoch: 135 loss : tensor(0.9254, grad_fn=<DivBackward0>)\n",
            "Epoch: 136 loss : tensor(0.9256, grad_fn=<DivBackward0>)\n",
            "Epoch: 137 loss : tensor(0.9251, grad_fn=<DivBackward0>)\n",
            "Epoch: 138 loss : tensor(0.9245, grad_fn=<DivBackward0>)\n",
            "Epoch: 139 loss : tensor(0.9248, grad_fn=<DivBackward0>)\n",
            "Epoch: 140 loss : tensor(0.9251, grad_fn=<DivBackward0>)\n",
            "Epoch: 141 loss : tensor(0.9243, grad_fn=<DivBackward0>)\n",
            "Epoch: 142 loss : tensor(0.9242, grad_fn=<DivBackward0>)\n",
            "Epoch: 143 loss : tensor(0.9235, grad_fn=<DivBackward0>)\n",
            "Epoch: 144 loss : tensor(0.9240, grad_fn=<DivBackward0>)\n",
            "Epoch: 145 loss : tensor(0.9233, grad_fn=<DivBackward0>)\n",
            "Epoch: 146 loss : tensor(0.9228, grad_fn=<DivBackward0>)\n",
            "Epoch: 147 loss : tensor(0.9224, grad_fn=<DivBackward0>)\n",
            "Epoch: 148 loss : tensor(0.9219, grad_fn=<DivBackward0>)\n",
            "Epoch: 149 loss : tensor(0.9221, grad_fn=<DivBackward0>)\n",
            "Epoch: 150 loss : tensor(0.9219, grad_fn=<DivBackward0>)\n",
            "Epoch: 151 loss : tensor(0.9217, grad_fn=<DivBackward0>)\n",
            "Epoch: 152 loss : tensor(0.9217, grad_fn=<DivBackward0>)\n",
            "Epoch: 153 loss : tensor(0.9215, grad_fn=<DivBackward0>)\n",
            "Epoch: 154 loss : tensor(0.9215, grad_fn=<DivBackward0>)\n",
            "Epoch: 155 loss : tensor(0.9210, grad_fn=<DivBackward0>)\n",
            "Epoch: 156 loss : tensor(0.9207, grad_fn=<DivBackward0>)\n",
            "Epoch: 157 loss : tensor(0.9203, grad_fn=<DivBackward0>)\n",
            "Epoch: 158 loss : tensor(0.9207, grad_fn=<DivBackward0>)\n",
            "Epoch: 159 loss : tensor(0.9210, grad_fn=<DivBackward0>)\n",
            "Epoch: 160 loss : tensor(0.9201, grad_fn=<DivBackward0>)\n",
            "Epoch: 161 loss : tensor(0.9206, grad_fn=<DivBackward0>)\n",
            "Epoch: 162 loss : tensor(0.9197, grad_fn=<DivBackward0>)\n",
            "Epoch: 163 loss : tensor(0.9196, grad_fn=<DivBackward0>)\n",
            "Epoch: 164 loss : tensor(0.9192, grad_fn=<DivBackward0>)\n",
            "Epoch: 165 loss : tensor(0.9189, grad_fn=<DivBackward0>)\n",
            "Epoch: 166 loss : tensor(0.9189, grad_fn=<DivBackward0>)\n",
            "Epoch: 167 loss : tensor(0.9184, grad_fn=<DivBackward0>)\n",
            "Epoch: 168 loss : tensor(0.9186, grad_fn=<DivBackward0>)\n",
            "Epoch: 169 loss : tensor(0.9183, grad_fn=<DivBackward0>)\n",
            "Epoch: 170 loss : tensor(0.9187, grad_fn=<DivBackward0>)\n",
            "Epoch: 171 loss : tensor(0.9185, grad_fn=<DivBackward0>)\n",
            "Epoch: 172 loss : tensor(0.9185, grad_fn=<DivBackward0>)\n",
            "Epoch: 173 loss : tensor(0.9179, grad_fn=<DivBackward0>)\n",
            "Epoch: 174 loss : tensor(0.9181, grad_fn=<DivBackward0>)\n",
            "Epoch: 175 loss : tensor(0.9177, grad_fn=<DivBackward0>)\n",
            "Epoch: 176 loss : tensor(0.9176, grad_fn=<DivBackward0>)\n",
            "Epoch: 177 loss : tensor(0.9173, grad_fn=<DivBackward0>)\n",
            "Epoch: 178 loss : tensor(0.9174, grad_fn=<DivBackward0>)\n",
            "Epoch: 179 loss : tensor(0.9178, grad_fn=<DivBackward0>)\n",
            "Epoch: 180 loss : tensor(0.9175, grad_fn=<DivBackward0>)\n",
            "Epoch: 181 loss : tensor(0.9169, grad_fn=<DivBackward0>)\n",
            "Epoch: 182 loss : tensor(0.9164, grad_fn=<DivBackward0>)\n",
            "Epoch: 183 loss : tensor(0.9165, grad_fn=<DivBackward0>)\n",
            "Epoch: 184 loss : tensor(0.9167, grad_fn=<DivBackward0>)\n",
            "Epoch: 185 loss : tensor(0.9163, grad_fn=<DivBackward0>)\n",
            "Epoch: 186 loss : tensor(0.9162, grad_fn=<DivBackward0>)\n",
            "Epoch: 187 loss : tensor(0.9162, grad_fn=<DivBackward0>)\n",
            "Epoch: 188 loss : tensor(0.9154, grad_fn=<DivBackward0>)\n",
            "Epoch: 189 loss : tensor(0.9159, grad_fn=<DivBackward0>)\n",
            "Epoch: 190 loss : tensor(0.9160, grad_fn=<DivBackward0>)\n",
            "Epoch: 191 loss : tensor(0.9155, grad_fn=<DivBackward0>)\n",
            "Epoch: 192 loss : tensor(0.9156, grad_fn=<DivBackward0>)\n",
            "Epoch: 193 loss : tensor(0.9157, grad_fn=<DivBackward0>)\n",
            "Epoch: 194 loss : tensor(0.9152, grad_fn=<DivBackward0>)\n",
            "Epoch: 195 loss : tensor(0.9156, grad_fn=<DivBackward0>)\n",
            "Epoch: 196 loss : tensor(0.9152, grad_fn=<DivBackward0>)\n",
            "Epoch: 197 loss : tensor(0.9155, grad_fn=<DivBackward0>)\n",
            "Epoch: 198 loss : tensor(0.9149, grad_fn=<DivBackward0>)\n",
            "Epoch: 199 loss : tensor(0.9150, grad_fn=<DivBackward0>)\n",
            "Epoch: 200 loss : tensor(0.9151, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "K5dVB-05C_ZA",
        "outputId": "a51702ac-fd89-47be-f612-4c17da30b3df"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = np.array(list(range(1,201, 1)))\n",
        "plt.plot(x, np.array(train_loss_list))\n",
        "plt.title(\" Training Loss \")\n",
        "plt.xlabel(\" No. of epochs \")\n",
        "plt.ylabel(\" Loss \")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bak5uc8gd-gX"
      },
      "source": [
        "## Testing the SAE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Js-hB2gMXY6",
        "outputId": "ea0b7ba7-eb1d-4e63-8be4-6e2f7b6b7556"
      },
      "source": [
        "epochs = 200\n",
        "train_loss_list = []\n",
        "\n",
        "test_loss = 0\n",
        "#excluding the users who did not rate\n",
        "s = 0.0 #float\n",
        "for id_user in range(nb_users):\n",
        "  input = training_set[id_user]\n",
        "  #here also we will keep it as training_set only as we want to predict the ratings for the movies which user has not watched yet\n",
        "  #then we will compare this with the data in the test  set as test set has the ratings which are not there in the training set\n",
        "  input = Variable(input).unsqueeze(0)#create a new dimenion at 0 index in shape\n",
        "  target = Variable(test_set[id_user].unsqueeze(0))\n",
        "  #output = sae(input)#additional dimenstion for the batch\n",
        "  if (torch.sum(input)>0):\n",
        "      output = sae(input) #these are rating for other movies\n",
        "      #optimizing memory and computation\n",
        "      target.require_grad =  False\n",
        "      output[target == 0] = 0\n",
        "      loss = criterion(output, target)\n",
        "      mean_corrector = nb_movies/(float(torch.sum(target.data>0)) + 1e-10)\n",
        "      test_loss = test_loss + torch.sqrt((loss*mean_corrector))\n",
        "      s = s + 1.\n",
        "print(\" Test Loss : \" + str(test_loss/s) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Test Loss : tensor(0.4636, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}